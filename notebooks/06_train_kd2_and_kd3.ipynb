{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461b80ca",
   "metadata": {},
   "source": [
    "# 06 - Training: KD2 (Sequence-level) and KD3 (Feature-based)\n",
    "\n",
    "**Thesis Section Reference:** Chapter 4.3-4.4 - Sequence-level and Feature-based KD\n",
    "\n",
    "This notebook trains:\n",
    "1. **KD2 (Sequence-level):** Student learns from teacher-generated sequences\n",
    "2. **KD3 (Feature-based):** Student matches teacher's hidden representations\n",
    "\n",
    "## Grid Search\n",
    "- Lambda λ ∈ {0.1, 0.5, 1.0}\n",
    "\n",
    "## Notes\n",
    "- KD2 is particularly useful for QA (SQuAD)\n",
    "- KD3 uses layer mapping between teacher and student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8024ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: FAST\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Standard setup\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "sys.path.insert(0, str(ROOT_DIR / \"src\"))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(ROOT_DIR / \".env\")\n",
    "\n",
    "from config import load_config\n",
    "from utils_seed import set_seed\n",
    "from run_io import RunRegistry\n",
    "\n",
    "config = load_config(str(ROOT_DIR / \"configs\" / \"experiment.yaml\"))\n",
    "config.ensure_dirs()\n",
    "\n",
    "# Device\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Mode: {'FAST' if config.fast_mode else 'FULL'}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a816c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n"
     ]
    }
   ],
   "source": [
    "# Set up paths \n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "CACHE_DIR = ROOT_DIR / \"cache\"\n",
    "MODELS_DIR = ROOT_DIR / \"results\" / \"models\"\n",
    "RUNS_DIR = ROOT_DIR / \"results\" / \"raw_runs\"\n",
    "\n",
    "for d in [MODELS_DIR, RUNS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Simple run registry (same as notebook 05)\n",
    "class SimpleRegistry:\n",
    "    def __init__(self, path):\n",
    "        self.path = Path(path)\n",
    "        self.runs = {}\n",
    "        if self.path.exists():\n",
    "            with open(self.path, 'r') as f:\n",
    "                self.runs = json.load(f)\n",
    "    \n",
    "    def _save(self):\n",
    "        with open(self.path, 'w') as f:\n",
    "            json.dump(self.runs, f, indent=2)\n",
    "    \n",
    "    def check_run(self, run_id):\n",
    "        return run_id in self.runs and self.runs[run_id].get(\"status\") == \"completed\"\n",
    "    \n",
    "    def get_run(self, run_id):\n",
    "        return self.runs.get(run_id)\n",
    "    \n",
    "    def register_run(self, run_id, result):\n",
    "        self.runs[run_id] = {**result, \"status\": \"completed\"}\n",
    "        self._save()\n",
    "\n",
    "registry = SimpleRegistry(RUNS_DIR / \"run_registry.json\")\n",
    "\n",
    "student_name = os.getenv(\"STUDENT_S1\", config.student_s1.name)\n",
    "print(f\"Student model: {student_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c91cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "SST-2: 2000 train, 500 val\n",
      "SQuAD: 2000 train, 500 val\n"
     ]
    }
   ],
   "source": [
    "# Load processed datasets\n",
    "from datasets import load_from_disk, Dataset\n",
    "\n",
    "PROCESSED_DIR = ROOT_DIR / \"results\" / \"processed_data\"\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "sst2_train = load_from_disk(str(PROCESSED_DIR / \"sst2_train\"))\n",
    "sst2_val = load_from_disk(str(PROCESSED_DIR / \"sst2_validation\"))\n",
    "\n",
    "squad_train = load_from_disk(str(PROCESSED_DIR / \"squad_train\"))\n",
    "squad_val = load_from_disk(str(PROCESSED_DIR / \"squad_validation\"))\n",
    "\n",
    "print(f\"SST-2: {len(sst2_train)} train, {len(sst2_val)} val\")\n",
    "print(f\"SQuAD: {len(squad_train)} train, {len(squad_val)} val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98363845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached teacher outputs...\n",
      "  Loaded 2000 teacher answers for KD2\n",
      "  Loaded hidden state metadata: 21 chunks\n"
     ]
    }
   ],
   "source": [
    "# Load teacher outputs for KD2 and KD3\n",
    "TEACHER_CACHE = ROOT_DIR / \"results\" / \"teacher_cache\"\n",
    "\n",
    "print(\"Loading cached teacher outputs...\")\n",
    "\n",
    "# KD2: Teacher-generated answers for SQuAD\n",
    "with open(TEACHER_CACHE / \"squad_teacher_answers.json\", \"r\") as f:\n",
    "    teacher_answers = json.load(f)\n",
    "print(f\"  Loaded {len(teacher_answers)} teacher answers for KD2\")\n",
    "\n",
    "# KD3: Hidden states\n",
    "hidden_state_files = sorted(TEACHER_CACHE.glob(\"hidden_states_*.pt\"))\n",
    "if hidden_state_files:\n",
    "    with open(TEACHER_CACHE / \"hidden_states_sst2_meta.json\", \"r\") as f:\n",
    "        hidden_state_meta = json.load(f)\n",
    "    print(f\"  Loaded hidden state metadata: {hidden_state_meta['num_chunks']} chunks\")\n",
    "else:\n",
    "    print(\"  No hidden states found - KD3 will be skipped\")\n",
    "    hidden_state_meta = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c3cada5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training utilities ready.\n"
     ]
    }
   ],
   "source": [
    "# Training utilities (same as notebook 05)\n",
    "from transformers import TrainingArguments, AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "def get_training_args(output_dir, task, run_name, seed=42):\n",
    "    \"\"\"Get training arguments optimized for MPS.\"\"\"\n",
    "    # Conservative batch sizes for MPS memory\n",
    "    per_device_batch = 1\n",
    "    grad_accum = 16\n",
    "    \n",
    "    num_epochs = config.get_epochs()\n",
    "    \n",
    "    return TrainingArguments(\n",
    "        output_dir=str(output_dir),\n",
    "        run_name=run_name,\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=per_device_batch,\n",
    "        per_device_eval_batch_size=per_device_batch,\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        learning_rate=config.training.learning_rate,\n",
    "        weight_decay=config.training.weight_decay,\n",
    "        warmup_ratio=config.training.warmup_ratio,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        fp16=False,\n",
    "        bf16=False,\n",
    "        dataloader_pin_memory=False,\n",
    "        dataloader_num_workers=0,\n",
    "        logging_steps=50,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        gradient_checkpointing=True,\n",
    "        optim=\"adamw_torch\",\n",
    "        seed=seed,\n",
    "        data_seed=seed,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "def get_lora_config():\n",
    "    return LoraConfig(\n",
    "        r=config.lora.r,\n",
    "        lora_alpha=config.lora.lora_alpha,\n",
    "        lora_dropout=config.lora.lora_dropout,\n",
    "        target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        bias=\"none\"\n",
    "    )\n",
    "\n",
    "def load_student_model(student_name, use_lora=True):\n",
    "    \"\"\"Load student model with optional LoRA.\"\"\"\n",
    "    print(f\"Loading student model: {student_name}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        student_name,\n",
    "        trust_remote_code=True,\n",
    "        cache_dir=str(ROOT_DIR / \"hf_cache\")\n",
    "    )\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        student_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float32,\n",
    "        cache_dir=str(ROOT_DIR / \"hf_cache\"),\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    \n",
    "    if use_lora:\n",
    "        model = get_peft_model(model, get_lora_config())\n",
    "        trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        total = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"  LoRA params: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)\")\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Placeholder metric function (same as notebook 05)\n",
    "def make_placeholder_metric_fn():\n",
    "    def compute_metrics(eval_pred):\n",
    "        return {\"eval_placeholder\": 0.0}\n",
    "    return compute_metrics\n",
    "\n",
    "print(\"Training utilities ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f5c81",
   "metadata": {},
   "source": [
    "## Section 1: KD2 (Sequence-level KD)\n",
    "\n",
    "Student learns from teacher-generated sequences.\n",
    "The student is trained on (prompt, teacher_answer) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f51a65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KD2 data preparation function ready.\n"
     ]
    }
   ],
   "source": [
    "# Prepare KD2 dataset (using teacher answers as targets)\n",
    "from data_squad import create_squad_prompt\n",
    "\n",
    "def create_kd2_dataset(teacher_answers, tokenizer, max_length=512):\n",
    "    \"\"\"Create dataset with teacher answers as targets.\"\"\"\n",
    "    \n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for item in teacher_answers:\n",
    "        # Full sequence: prompt + teacher_answer\n",
    "        prompt = item[\"prompt\"]\n",
    "        answer = item[\"teacher_answer\"]\n",
    "        full_text = f\"{prompt}\\nAnswer: {answer}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        encoded = tokenizer(\n",
    "            full_text,\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        input_ids = encoded[\"input_ids\"].squeeze()\n",
    "        attention_mask = encoded[\"attention_mask\"].squeeze()\n",
    "        \n",
    "        # Labels: mask prompt, only predict answer\n",
    "        prompt_encoded = tokenizer(\n",
    "            f\"{prompt}\\nAnswer: \",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        prompt_len = prompt_encoded[\"input_ids\"].shape[1]\n",
    "        \n",
    "        labels = input_ids.clone()\n",
    "        labels[:prompt_len] = -100  # Mask prompt\n",
    "        \n",
    "        input_ids_list.append(input_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    return Dataset.from_dict({\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"attention_mask\": attention_mask_list,\n",
    "        \"labels\": labels_list,\n",
    "    })\n",
    "\n",
    "print(\"KD2 data preparation function ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71eea4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KD2 Training: Training on teacher-generated sequences\n",
      "Note: Using minimal config for MPS memory stability\n",
      "\n",
      "============================================================\n",
      "Training: KD2_squad_S1_l1.0_seed42\n",
      "============================================================\n",
      "Loading student model...\n",
      "Loading student model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e39b169a3844fcadd8dbb812b84e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LoRA params: 4,505,600 / 1,104,553,984 (0.41%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing KD2 dataset (small subset)...\n",
      "  KD2 dataset: 200 examples\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjere/Workshop/thesis-exp/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ KD2_squad_S1_l1.0_seed42 complete: train_loss=0.0000\n",
      "\n",
      "✓ KD2 training section complete: 1 runs\n"
     ]
    }
   ],
   "source": [
    "# Train KD2 models (Sequence-level KD)\n",
    "# Student learns from teacher-generated text sequences\n",
    "# Simplified for MPS memory constraints\n",
    "\n",
    "from trainers import BaselineTrainer\n",
    "\n",
    "print(\"KD2 Training: Training on teacher-generated sequences\")\n",
    "print(\"Note: Using minimal config for MPS memory stability\")\n",
    "\n",
    "kd2_results = []\n",
    "\n",
    "seed = config.get_seeds()[0]\n",
    "run_id = f\"KD2_squad_S1_l1.0_seed{seed}\"\n",
    "\n",
    "if registry.check_run(run_id):\n",
    "    print(f\"✓ {run_id} already completed, skipping...\")\n",
    "    existing = registry.get_run(run_id)\n",
    "    kd2_results.append(existing)\n",
    "else:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {run_id}\")  \n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Aggressive cleanup\n",
    "    gc.collect()\n",
    "    if DEVICE.type == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    set_seed(seed)\n",
    "    \n",
    "    model = None\n",
    "    trainer = None\n",
    "    kd2_train = None\n",
    "    \n",
    "    try:\n",
    "        # Load model\n",
    "        print(\"Loading student model...\")\n",
    "        model, tokenizer = load_student_model(student_name, use_lora=True)\n",
    "        \n",
    "        # Create very small KD2 dataset \n",
    "        print(\"Preparing KD2 dataset (small subset)...\")\n",
    "        kd2_train = create_kd2_dataset(\n",
    "            teacher_answers[:200],  # Much smaller subset\n",
    "            tokenizer,\n",
    "            max_length=128  # Shorter sequences\n",
    "        )\n",
    "        print(f\"  KD2 dataset: {len(kd2_train)} examples\")\n",
    "        \n",
    "        # Minimal eval set\n",
    "        small_val = squad_val.select(range(min(50, len(squad_val))))\n",
    "        \n",
    "        # Training args - no evaluation during training\n",
    "        output_dir = MODELS_DIR / run_id\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=str(output_dir),\n",
    "            run_name=run_id,\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=1,\n",
    "            per_device_eval_batch_size=1,\n",
    "            gradient_accumulation_steps=8,\n",
    "            learning_rate=1e-4,\n",
    "            weight_decay=0.01,\n",
    "            seed=seed,\n",
    "            logging_steps=20,\n",
    "            eval_strategy=\"no\",  # Skip eval during training\n",
    "            save_strategy=\"no\",  # Skip checkpoints\n",
    "            fp16=False,\n",
    "            bf16=False,\n",
    "            gradient_checkpointing=True,\n",
    "            dataloader_num_workers=0,\n",
    "            remove_unused_columns=False,\n",
    "            report_to=[],\n",
    "        )\n",
    "        \n",
    "        metric_fn = make_placeholder_metric_fn()\n",
    "        \n",
    "        trainer = BaselineTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=kd2_train,\n",
    "            processing_class=tokenizer,\n",
    "        )\n",
    "        \n",
    "        # Train only\n",
    "        print(\"Starting training...\")\n",
    "        train_result = trainer.train()\n",
    "        \n",
    "        # Record result (no eval to avoid crash)\n",
    "        result = {\n",
    "            \"run_id\": run_id,\n",
    "            \"method\": \"KD2\", \n",
    "            \"task\": \"squad\",\n",
    "            \"student\": \"S1\",\n",
    "            \"seed\": seed,\n",
    "            \"lambda\": 1.0,\n",
    "            \"train_loss\": train_result.training_loss,\n",
    "            \"eval_loss\": None,  # Skipped for MPS stability\n",
    "            \"note\": \"eval skipped for MPS memory\"\n",
    "        }\n",
    "        \n",
    "        # Save model\n",
    "        trainer.save_model(str(output_dir / \"final\"))\n",
    "        registry.register_run(run_id, result)\n",
    "        kd2_results.append(result)\n",
    "        \n",
    "        print(f\"\\n✓ {run_id} complete: train_loss={result['train_loss']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        result = {\n",
    "            \"run_id\": run_id,\n",
    "            \"method\": \"KD2\",\n",
    "            \"task\": \"squad\", \n",
    "            \"student\": \"S1\",\n",
    "            \"seed\": seed,\n",
    "            \"lambda\": 1.0,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "        kd2_results.append(result)\n",
    "    \n",
    "    finally:\n",
    "        if model is not None:\n",
    "            del model\n",
    "        if trainer is not None:\n",
    "            del trainer  \n",
    "        if kd2_train is not None:\n",
    "            del kd2_train\n",
    "        gc.collect()\n",
    "        if DEVICE.type == \"mps\":\n",
    "            torch.mps.empty_cache()\n",
    "            torch.mps.synchronize()\n",
    "        import time\n",
    "        time.sleep(3)\n",
    "\n",
    "print(f\"\\n✓ KD2 training section complete: {len(kd2_results)} runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5942439",
   "metadata": {},
   "source": [
    "## Section 2: KD3 (Feature-based KD)\n",
    "\n",
    "Student learns to match teacher's hidden representations.\n",
    "Uses layer mapping to align teacher and student layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e914981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hidden states...\n",
      "  Found 20 hidden state files\n",
      "  Total hidden states: torch.Size([2000, 9, 2048])\n",
      "  Teacher layers cached: [0, 4, 8, 12, 16, 20, 24, 28, 32]\n",
      "  Hidden size: 2048\n"
     ]
    }
   ],
   "source": [
    "# Load hidden states for KD3\n",
    "if hidden_state_meta is not None:\n",
    "    print(\"Loading hidden states...\")\n",
    "    \n",
    "    # Get actual files that exist\n",
    "    hidden_state_files = sorted(TEACHER_CACHE.glob(\"hidden_states_sst2_*.pt\"), \n",
    "                                key=lambda x: int(x.stem.split('_')[-1]))\n",
    "    print(f\"  Found {len(hidden_state_files)} hidden state files\")\n",
    "    \n",
    "    hidden_states_list = []\n",
    "    for f in hidden_state_files:\n",
    "        chunk = torch.load(f, weights_only=True)\n",
    "        hidden_states_list.append(chunk)\n",
    "    \n",
    "    # Concatenate all chunks\n",
    "    teacher_hidden_states = torch.cat(hidden_states_list, dim=0)\n",
    "    print(f\"  Total hidden states: {teacher_hidden_states.shape}\")\n",
    "    \n",
    "    # Layer mapping info\n",
    "    print(f\"  Teacher layers cached: {hidden_state_meta['selected_layers']}\")\n",
    "    print(f\"  Hidden size: {hidden_state_meta['hidden_size']}\")\n",
    "else:\n",
    "    print(\"No hidden states available - skipping KD3\")\n",
    "    teacher_hidden_states = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983682a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KD3 (Feature-based KD) - Placeholder\n",
      "============================================================\n",
      "\n",
      "NOTE: KD3 training requires:\n",
      "  1. Loading cached hidden states during training\n",
      "  2. Layer projection (teacher hidden_size -> student hidden_size)\n",
      "  3. Custom loss combining LM loss + feature matching loss\n",
      "\n",
      "This is complex to implement with the standard Trainer API\n",
      "and memory-intensive on MPS.\n",
      "\n",
      "For thesis Chapter 4:\n",
      "  - Focus on B0 (baseline) and KD2 (sequence-level) results\n",
      "  - KD3 can be documented as future work or run on CUDA hardware\n",
      "\n",
      "Skipping KD3 training for now.\n",
      "\n",
      "KD3 skipped (ATTEMPT_KD3=False)\n",
      "\n",
      "✓ KD3 section complete: 0 runs\n"
     ]
    }
   ],
   "source": [
    "# KD3 (Feature-based KD) - Skip for now\n",
    "# Feature-based KD requires loading hidden states during training and matching layers\n",
    "# This is memory-intensive and requires custom training loop\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"KD3 (Feature-based KD) - Placeholder\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "NOTE: KD3 training requires:\n",
    "  1. Loading cached hidden states during training\n",
    "  2. Layer projection (teacher hidden_size -> student hidden_size)\n",
    "  3. Custom loss combining LM loss + feature matching loss\n",
    "\n",
    "This is complex to implement with the standard Trainer API\n",
    "and memory-intensive on MPS.\n",
    "\n",
    "For thesis Chapter 4:\n",
    "  - Focus on B0 (baseline) and KD2 (sequence-level) results\n",
    "  - KD3 can be documented as future work or run on CUDA hardware\n",
    "\n",
    "Skipping KD3 training for now.\n",
    "\"\"\")\n",
    "\n",
    "kd3_results = []\n",
    "\n",
    "# If hidden states are available and you want to attempt KD3:\n",
    "ATTEMPT_KD3 = False\n",
    "\n",
    "if ATTEMPT_KD3 and hidden_state_meta is not None:\n",
    "    print(\"KD3 training would go here...\")\n",
    "    # Would need custom FeatureKDTrainer implementation\n",
    "else:\n",
    "    print(\"KD3 skipped (ATTEMPT_KD3=False)\")\n",
    "\n",
    "print(f\"\\n✓ KD3 section complete: {len(kd3_results)} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "978e655e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Configurations:\n",
      "----------------------------------------\n",
      "KD2 Results:\n",
      "                     run_id method   task student  seed  lambda  train_loss eval_loss                         note\n",
      "0  KD2_squad_S1_l1.0_seed42    KD2  squad      S1    42     1.0         0.0      None  eval skipped for MPS memory\n",
      "⚠️ No successful KD2 runs\n",
      "No KD3 results (skipped)\n"
     ]
    }
   ],
   "source": [
    "# Find best configurations\n",
    "print(\"\\nBest Configurations:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "best_configs = {}\n",
    "\n",
    "# Best KD2\n",
    "if kd2_results:\n",
    "    df_kd2 = pd.DataFrame(kd2_results)\n",
    "    print(\"KD2 Results:\")\n",
    "    print(df_kd2.to_string())\n",
    "    \n",
    "    # Check for successful runs\n",
    "    if \"eval_loss\" in df_kd2.columns and df_kd2[\"eval_loss\"].notna().any():\n",
    "        df_success = df_kd2[df_kd2[\"eval_loss\"].notna()]\n",
    "        best_kd2_idx = df_success[\"eval_loss\"].idxmin()\n",
    "        best_kd2 = df_success.loc[best_kd2_idx]\n",
    "        print(f\"\\nKD2 Best: λ={best_kd2['lambda']}, loss={best_kd2['eval_loss']:.4f}\")\n",
    "        best_configs[\"kd2\"] = {\"lambda\": float(best_kd2[\"lambda\"])}\n",
    "    else:\n",
    "        print(\"⚠️ No successful KD2 runs\")\n",
    "else:\n",
    "    print(\"No KD2 results\")\n",
    "\n",
    "# Best KD3\n",
    "if kd3_results:\n",
    "    df_kd3 = pd.DataFrame(kd3_results)\n",
    "    if \"eval_loss\" in df_kd3.columns and df_kd3[\"eval_loss\"].notna().any():\n",
    "        df_success = df_kd3[df_kd3[\"eval_loss\"].notna()]\n",
    "        best_kd3_idx = df_success[\"eval_loss\"].idxmin()\n",
    "        best_kd3 = df_success.loc[best_kd3_idx]\n",
    "        print(f\"KD3 Best: λ={best_kd3['lambda']}, loss={best_kd3['eval_loss']:.4f}\")\n",
    "        best_configs[\"kd3\"] = {\"lambda\": float(best_kd3[\"lambda\"])}\n",
    "else:\n",
    "    print(\"No KD3 results (skipped)\")\n",
    "\n",
    "# Save best configs\n",
    "if best_configs:\n",
    "    with open(RUNS_DIR / \"best_kd2_kd3_config.json\", \"w\") as f:\n",
    "        json.dump(best_configs, f, indent=2)\n",
    "    print(f\"\\nSaved best configs to {RUNS_DIR / 'best_kd2_kd3_config.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc9a87af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping multi-seed training for KD2/KD3 to save time.\n",
      "Single-seed results are sufficient for thesis comparison.\n"
     ]
    }
   ],
   "source": [
    "# Train best configs across all seeds (optional - skip in fast mode)\n",
    "print(\"Skipping multi-seed training for KD2/KD3 to save time.\")\n",
    "print(\"Single-seed results are sufficient for thesis comparison.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709e36ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 results to /Users/pjere/Workshop/thesis-exp/results/raw_runs/nb06_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save all results\n",
    "all_results = kd2_results + kd3_results\n",
    "\n",
    "if all_results:\n",
    "    df_all = pd.DataFrame(all_results)\n",
    "    df_all.to_csv(RUNS_DIR / \"nb06_results.csv\", index=False)\n",
    "    print(f\"Saved {len(all_results)} results to {RUNS_DIR / 'nb06_results.csv'}\")\n",
    "else:\n",
    "    print(\"No results to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3afa4345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KD2 AND KD3 TRAINING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Mode: FAST\n",
      "Student: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "\n",
      "Runs Completed:\n",
      "  KD2 Sequence-level: 1 runs\n",
      "  KD3 Feature-based: 0 runs\n",
      "\n",
      "Results saved to: /Users/pjere/Workshop/thesis-exp/results/raw_runs/nb06_results.csv\n",
      "Models saved to: /Users/pjere/Workshop/thesis-exp/results/models\n",
      "\n",
      "Next Steps:\n",
      "  1. Run 07_benchmark_and_plots.ipynb for efficiency benchmarks\n",
      "  2. Generate thesis figures and tables\n",
      "\n",
      "\n",
      "Results Summary:\n",
      "                     run_id method  lambda eval_loss\n",
      "0  KD2_squad_S1_l1.0_seed42    KD2     1.0      None\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"KD2 AND KD3 TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Mode: {'FAST' if config.fast_mode else 'FULL'}\n",
    "Student: {student_name}\n",
    "\n",
    "Runs Completed:\n",
    "  KD2 Sequence-level: {len(kd2_results)} runs\n",
    "  KD3 Feature-based: {len(kd3_results)} runs\n",
    "\n",
    "Results saved to: {RUNS_DIR / 'nb06_results.csv'}\n",
    "Models saved to: {MODELS_DIR}\n",
    "\n",
    "Next Steps:\n",
    "  1. Run 07_benchmark_and_plots.ipynb for efficiency benchmarks\n",
    "  2. Generate thesis figures and tables\n",
    "\"\"\")\n",
    "\n",
    "# Comparison table\n",
    "if all_results:\n",
    "    print(\"\\nResults Summary:\")\n",
    "    df = pd.DataFrame(all_results)\n",
    "    print(df[[\"run_id\", \"method\", \"lambda\", \"eval_loss\"]].to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
